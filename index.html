<!DOCTYPE html>
<html lang='en'>

<head>
    <base href=".">
    <link rel="shortcut icon" type="image/png" href="assets/favicon.png"/>
    <link rel="stylesheet" type="text/css" media="all" href="assets/main.css"/>
    <meta name="description" content="Conference Template">
    <meta name="resource-type" content="document">
    <meta name="distribution" content="global">
    <meta name="KeyWords" content="Conference">
    <title>Small-Object Recognition using Multi-Media Sensing</title>
</head>

<body>

    <div class="banner">
        <img src="assets/Academic.jpg" alt="Conference Template Banner">
        <div class="top-left">
            <span class="title1">Conference</span><span class="title2">Template</span> <span class="year">2525</span>
        </div>
        <div class="bottom-right">
            June 31, 2525 <br> University Name, and City Maybe
        </div>
    </div>

    <table class="navigation">
        <tr>
            <td class="navigation">
                <a class="current" title="Conference Home Page" href=".">Home</a>
            </td>
            <td class="navigation">
                <a title="Register for the Conference" href="registration">Registration</a>
            </td>
            <td class="navigation">
                <a title="Conference Program" href="program">Program</a> 
            </td>
            <td class="navigation">
                <a title="Directions to the Conference" href="directions">Directions</a>
            </td>
            <td class="navigation">
                <a title="Conference Flyer" href="flyer">Flyer</a>
            </td>
        </tr>
    </table>

    <h2>Scope and topics of the workshop.</h2>
    <p>
        Recent advancements in deep learning, particularly with the rise of convolutional neural
        networks and Vision Transformers, have led to significant progress in recognition tasks such 
        as object detection and segmentation. However, despite these strides, recognizing small 
        objects remains a challenging task. Challenges arise from the inherent visual complexity and 
	noisy representations of small objects, difficulties in annotation due to association blur, the 
        bottleneck in dataset expansion, and the lack of well-established evaluation metrics specific 
	to small object recognition.    
    </p>
    <p>
        The recognition of small objects holds crucial applications in various fields such as 
	healthcare, autonomous mobility, satellite imaging, automotive, maritime, and structural 
	measurements. Specific applications include tumor detection, distant bird identification,
	satellite-based object detection, recognition of marine life underwater, and defect detection. 
	While previous research has predominantly focused on RGB image media and, in the
	medical field, extended to MRI, CT, and X-ray images, leveraging a multitude of media such
	as NIR, IR, event cameras, ultrasound imaging, and LiDAR in multimedia research is
	anticipated to be a significant breakthrough in addressing these challenges.
	    
    </p>
    <p>
        Inspired by these considerations, we propose hosting an ACM Multimedia workshop in 
        collaboration with ACM Multimedia (MM2024) in Melbourne in November 2024, titled 
	"Small-Object Recognition using Multimodal Sensing." This workshop aims to showcase the 
	latest research trends in small object recognition with two invited speakers. Additionally, it  
	provides a platform for presenting and discussing research outcomes in small object 
	detection accepted at the workshop.
    </p>
　　<p>
	The workshop will focus on algorithms, hardware, and system integration related to small
	object detection, welcoming contributions across various media, including RGB images, NIR, 
	IR, event cameras, and ultrasound imaging.
　 </p>
    <h2>Call for papers</h2>
	<p>
         <td> Submission<br />
	 <td>	The workshop uses OpenReview for paper submission and peer review. Paper submissions must conform with the “double-blind” review policy.<br />
         </p>
	<p>
         <td> Paper Format<br />
	 <td>	The same rule as for the main conference (ACM Multimedia 2024). Submissions can be of varying length from 4 to 8 pages, plus additional pages for the reference pages.<br />
         </p>
	<p>
         <td> Originality<br />
	 <td>	Papers submitted to the workshop must be the original work of the authors. Authors should be aware of the ACM policy with regard to plagiarism and self-plagiarism..<br />
         </p>
	<p>
         <td> Important dates<br />
	 <td>	Paper Submission Deadline		July19, 2024<br />
	<td>	Paper Acceptance Notification	August 5, 2024<br />
	<td>	Camera Ready Version		August 19, 2024<br />
	<td>	Workshop Date			October 28, 2024 (To Be Confirmed)<br />
         </p>
	
    <h2>Organizers</h2>
    <p>
       
    </p>

<table border="1">
  <tr>
    <td><img alt="" height="240" src="assets/kondo3.jpg" width="180" /><br />
				<a href="https://yuki-11.github.io/" target="_blank">Yuki Kondo<br />
				Toyota Motor Corporation</td>
       <td><img alt="" height="240" src="assets/Akita3.png" width="180" /><br />
				<a href="https://kakitamedia.github.io/homepage/" target="_blank">Kazutoshi Akita<br />
				Toyota Technological Institute</td>
    <td><img alt="" height="240" src="assets/ukita3.jpg" width="180" /><br />
				<a href="http://ypcfs/usr2/s13www/iim/ukita/index.html" target="_blank">Norimichi Ukita<br />
				Toyota Technological Institute</td>
  </tr>
　<tr>
    <td><img alt="" height="240" src="assets/Zhenjun Han3.jpg" width="180" /><br />
				<a href="https://people.ucas.ac.cn/~hanzhj?language=en" target="_blank">Zhenjun Han<br />
				University of Chinese Academy of Science </td>
       <td><img alt="" height="240" src="assets/Xuehui Yu3.jpg" width="180" /><br />
				<a href="https://yinglang.github.io/" target="_blank">Xuehui Yu<br />
				University of Chinese Academy of Sciences</td>
    <td><img alt="" height="240" src="assets/Aref Miri Rekavandi3.jpg" width="180" /><br />
				<a href="https://arekavandi.github.io/" target="_blank">Aref Miri Rekavandi <br />
				The University of Melbourne</td>
  </tr>
　<tr>
    <td><img alt="" height="240" src="assets/Lian Xu3.webp" width="180" /><br />
				<a href="https://research-repository.uwa.edu.au/en/persons/lian-xu" target="_blank">Lian Xu<br />
				University of Western Australia</td>
       <td><img alt="" height="240" src="assets/Farid Boussaid3.jpg" width="180" /><br />
				<a href="https://research-repository.uwa.edu.au/en/persons/farid-boussaid" target="_blank">Farid Boussaid<br />
				University of Western Australia</td>
    <td><img alt="" height="240" src="assets/Mohammed Bennamoun3.jpg" width="180" /><br />
				<a href="https://research-repository.uwa.edu.au/en/persons/mohammed-bennamoun" target="_blank">Mohammed Bennamoun<br />
				University of Western Australia</td>
  </tr>


</table>
 <h2>Advisory Committee</h2>
    <p>
        
    </p>

<table border="1">
  <tr>
    <td><img alt="" height="240" src="assets/SATO Yoichi5.jpg" width="180" /><br />
				<a href="https://sites.google.com/ut-vision.org/ysato/" target="_blank">Yoichi Sato<br />
				University of Tokyo</td>
       <td><img alt="" height="240" src="assets/saito_hideo3.jpg" width="180" /><br />
				<a href="https://www.hvrl.ics.keio.ac.jp/professor-saito/" target="_blank">Hideo Saito<br />
				Keio University</td>
    <td><img alt="" height="240" src="assets/Ming Hsuan Yang3.jpg" width="180" /><br />
				<a href="https://faculty.ucmerced.edu/mhyang/" target="_blank">Ming-Hsuan Yang<br />
				University of California at Merced; Google</td>
  </tr>	
</table>
<h2>Invited speakers</h2>
    <p>
        
    </p>

<table border="1">
  <tr>
    <td><img alt="" height="240" src="assets/Wanli-New3.jpg" width="180" /><br />
				<a href="https://wlouyang.github.io/" target="_blank">Wanli Ouyang<br />
				Shanghai AI Lab</td>
       <td><img alt="" height="240" src="assets/salman3.png" width="180" /><br />
				<a href="https://salman-h-khan.github.io/" target="_blank">Salman Khan<br />
				MBZUAI, Australian National University</td>
    
  </tr>	
</table>





    <footer>
        &copy; Conference Organizers
        &nbsp;|&nbsp; Design by <a href="https://github.com/mikepierce">Mike Pierce</a>
    </footer>

</body>
</html>

